# 入门数据分析-学术前沿趋势

## 贡献者信息
| 姓名                                                         | 介绍                                                         | 个人主页                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 刘羽中 | 数据科学从业者，Datawhale成员 |   https://www.zhihu.com/people/finlayliu      |
| 杨毅远 | 清华大学，Datawhale成员 |   https://github.com/yyysjz1997      |
| 张晋   | 北京理工大学，Datawhale成员 |   https://blog.csdn.net/weixin_44585839      |
| 雷钲仪   | 华东师范大学，Datawhale成员 |         |
| 周郴莲   | 东北石油大学，Datawhale成员 |     https://blog.csdn.net/weixin_42691585    |
| 宋怡然   | 上海交通大学，Datawhale成员 |     https://blog.csdn.net/weixin_42691585    |



## 致谢
特别感谢 [@LSGOMYP](https://github.com/LSGOMYP) 对本项目的帮助与支持。

## 关注我们

<div align=center><img src="https://raw.githubusercontent.com/datawhalechina/pumpkin-book/master/res/qrcode.jpeg" width = "250" height = "270" alt="Datawhale是一个专注AI领域的开源组织，以“for the learner，和学习者一起成长”为愿景，构建对学习者最有价值的开源学习社区。关注我们，一起学习成长。"></div>

## 学习主题

赛题以数据分析为背景，要求选手使用公开的arXiv论文完成对应的数据分析操作。与之前的数据挖掘赛题不同，本次赛题不仅要求选手对数据进行建模，而且需要选手利用赛题数据完成具体的可视化分析。

为更好的引导大家入门，我们同时为本赛题定制了系列学习方案，其中包括数据科学库使用（Pandas、Numpy和Matplotlib）、数据分析介绍和数据分析工具使用三部分。通过对本方案的完整学习，可以帮助掌握数据分析基本技能。同时我们也将提供专属的视频直播学习通道。

## 学习任务

### 任务1

- 学习主题：论文数量统计（数据统计任务），统计2019年全年，计算机各个方向论文数量；
- 学习内容：赛题理解、`Pandas`读取数据、数据统计 
- 学习成果：学习`Pandas`基础

### 任务2

- 学习主题：论文作者统计（数据统计任务），统计所有论文作者出现评率Top10的姓名；
- 学习内容：作者姓名识别和统计
- 学习成果：学习字符串基本操作、`Matplotlib`基础使用、`Seaborn`基础使用

### 任务3

- 学习主题：论文代码统计（数据统计任务），统计所有论文类别下包含源代码论文的比例；
- 学习内容：代码链接识别和统计
- 学习成果：学会使用正则表达式

### 任务4

- 学习主题：论文分类（数据建模任务），利用已有数据建模，对新论文进行类别分类；
- 学习内容：使用论文标题完成类别分类
- 学习成果：学会文本分类的基本方法、`TFIDF`等

### 任务5

- 学习主题：作者关联（数据建模任务），对论文作者关系进行建模，统计最常出现的作者关系；
- 学习内容：构建作者关系图，挖掘作者关系
- 学习成果：论文作者知识图谱、图关系挖掘

# 赛题介绍

## 赛题背景

本次新人赛是Datawhale与天池联合发起的0基础入门系列赛事第五场 —— 零基础入门数据分析之学术前沿趋势分析。

赛题以数据分析为背景，要求选手使用公开的arXiv论文完成对应的数据分析操作。与之前的数据挖掘赛题不同，本次赛题不仅要求选手对数据进行建模，而且需要选手利用赛题数据完成具体的可视化分析。

为更好的引导大家入门，我们同时为本赛题定制了系列学习方案，其中包括数据科学库使用（Pandas、Numpy和Matplotlib）、数据分析介绍和数据分析工具使用三部分。通过对本方案的完整学习，可以帮助掌握数据分析基本技能。同时我们也将提供专属的视频直播学习通道。

### 赛制说明

本次赛事分为两个阶段，分别为正式赛及长期赛。

#### 正式赛

正式赛分析初赛和复赛。初赛提供打分排行榜，初赛排行榜Top50经过代码审核获得复赛资格；复赛根据选手的可视化结果完成最终的排名计算。

- 初赛赛制：
  选手报名成功后，选手下载数据，在初赛阶段可以本地完成数据统计分析，通过赛题页左侧提交入口提交结果；
  初赛阶段提交后将进行实时评测；每天每支队伍可提交2次；排行榜每小时更新，按照评测指标得分从高到低排序；排行榜将选择历史最优成绩进行展示；

- 复赛赛制：
  在复赛阶段，选手沿用初赛的赛题数据。根据自身需要完成数据分析，并进行可视化等相应操作。
  复赛阶段需要所有选手在规定时间完成，并将可视化结果和代码公布在比赛论坛内部，并根据大众评审（帖子star数量）和举办方评审后得到最终排名；

#### 长期赛

在正式赛后，本场比赛将长期开放，报名和参赛无时间限制。
每天每位参赛选手可提交3次完成初赛打分；排行榜每小时更新，按照评测指标得分从高到低排序；排行榜将选择历史最优成绩进行展示；


## 赛题数据

### 数据说明

arXiv 重要的学术公开网站，也是搜索、浏览和下载学术论文的重要工具。arXiv论文涵盖的范围非常广，涉及物理学的庞大分支和计算机科学的众多子学科，如数学、统计学、电气工程、定量生物学和经济学等等。

本次赛题将使用arXiv在公开的170万篇论文数据集，希望各位选手通过数据分析能够挖掘出最近学术的发展趋势和学术关键词。

arXiv公开的数据集格式如下：

- `id`：arXiv ID，可用于访问论文；
- `submitter`：论文提交者；
- `authors`：论文作者；
- `title`：论文标题；
- `comments`：论文页数和图表等其他信息；
- `journal-ref`：论文发表的期刊；
- `doi`：数字对象标识符；
- `abstract`：论文摘要；
- `categories`：论文在 arXiv 系统的所属类别或标签；
- `versions`：论文版本。

数据集来源：
[https://www.kaggle.com/Cornell-University/arxiv](https://www.kaggle.com/Cornell-University/arxiv)

### 评测标准

在初赛阶段，需要参赛选手统计如下统计任务：

- 任务1：论文数量统计（数据统计任务）：统计2019年全年，计算机各个方向论文数量；
- 任务2：论文作者统计（数据统计任务）：统计所有论文作者出现评率Top10的姓名；
- 任务3：论文代码统计（数据统计任务）：统计所有论文类别下包含源代码论文的比例；
- 任务4：论文分类（数据建模任务）：利用已有数据建模，对新论文进行类别分类；
- 任务5：作者关联（数据建模任务）：对论文作者关系进行建模，统计最常出现的作者关系；

初赛阶段评分规则：利用准确率进行打分，选手可以在天池平台提交结果参与排行。

在复赛阶段，需要参赛选手完成自己的可视化任务（可自定义任务和具体分析目标），以下任务仅供参考：

- 任务1：统计分析每个类别论文在不同时期的热门关键词，分析arXiv论文常见关键词的发展趋势，并进行统计可视化；
- 任务2：统计分析每个类别论文综述句子的长度、情感和定冠词，并进行可视化；
- 任务3：统计分析论文作者的关联度，通过关联挖掘进行分析；

复赛阶段评分规则：根据需要参赛选手在天池论坛公开代码，并以统计时期帖子star数量为标准（star相同则以fork为标准，fork相同则以浏览量为标准）。







